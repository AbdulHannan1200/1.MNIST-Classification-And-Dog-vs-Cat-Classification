{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mnist dataset-> 28x28 pixel images of hand written digits 0-9\n",
    "mnist = tf.keras.datasets.mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 0.3174 - accuracy: 0.9123\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2b11232b978>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_train,y_train),(X_test,y_test) = mnist.load_data()\n",
    "#normalizing\n",
    "X_train=tf.keras.utils.normalize(X_train,axis=1)\n",
    "X_test=tf.keras.utils.normalize(X_test,axis=1)\n",
    "#Sequencial Model->Simplest one so called Feed Forward\n",
    "model=tf.keras.models.Sequential()\n",
    "#28x28 pixels image is there, so we don't need multi dimensional array we just need simple flattern layer\n",
    "model.add(tf.keras.layers.Flatten())#Input Layer\n",
    "#Hidden Layers\n",
    "model.add(tf.keras.layers.Dense(128,activation=tf.nn.relu))#rectified linear\n",
    "#how many units i.e. neurons in the hidden layer u want plus which type of activation function ou want to apply\n",
    "'''\n",
    "function that results in 0 if the input is negative, and the input itself if that input is 0 or positive. \n",
    "This specific add-on function (or better \"activation function\") is called a relu.\n",
    "The derivative of ReLU:\n",
    " 1 if x > 0\n",
    " 0 otherwise \n",
    "'''\n",
    "#2nd Hidden Layer\n",
    "#model.add(tf.keras.layers.Dense(128,activation=tf.nn.relu))\n",
    "#Output Lyer\n",
    "model.add(tf.keras.layers.Dense(10,activation=tf.nn.softmax))\n",
    "'''\n",
    "The easiest way I can think of to make you understand is: say you are given a tensor of shape (s1, s2, s3, s4) \n",
    "and as you mentioned you want to have the sum of all the entries along the last axis to be 1.\n",
    "\n",
    "sum = torch.sum(input, dim = 3) # input is of shape (s1, s2, s3, s4)\n",
    "Then you should call the softmax as:\n",
    "\n",
    "softmax(input, dim = 3)\n",
    "To understand easily, you can consider a 4d tensor of shape (s1, s2, s3, s4) as a 2d tensor or matrix of shape (s1*s2*s3, s4). Now if you want the matrix to contain values in each row (axis=0) or column (axis=1) that sum to 1, then, you can simply call the softmax function on the 2d tensor as follows:\n",
    "\n",
    "softmax(input, dim = 0) # normalizes values along axis 0\n",
    "softmax(input, dim = 1) # normalizes values along axis 1\n",
    "x = [[1,2],\n",
    "    [3,4]]\n",
    "do you want your final result to be\n",
    "\n",
    "y = [[0.27,0.73],\n",
    "    [0.27,0.73]]\n",
    "or\n",
    "\n",
    "y = [[0.12,0.12],\n",
    "    [0.88,0.88]]\n",
    "If it's the first option then you want dim = 1. If it's the second option you want dim = 0.\n",
    "'''\n",
    "#loss->degree of error\n",
    "#neural networks never tries to increase accuracy instead it tries best to minimze loss\n",
    "#optimizer->something like basic gradient descent\n",
    "#sparse ki jaga binary use krsty jab cat vs dog kr rhy\n",
    "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "model.fit(X_train,y_train,epochs=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-61145de0dcdc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mval_loss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mval_accuracy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Validation Loss:'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mval_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Validation Accuracy:'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mval_accuracy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "val_loss,val_accuracy=model.evaluate(X_test,y_test)\n",
    "print('Validation Loss:',val_loss)\n",
    "print('Validation Accuracy:',val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-99e7ba424260>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#print(X_train[0])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(X_train[0],cmap=plt.cm.binary)\n",
    "plt.show()\n",
    "#print(X_train[0])\n",
    "#0-255 pixels data, we should scaled data(normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "print(y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Abdul Hannan\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: epic_num_reader.model\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('epic_num_reader.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model=tf.keras.models.load_model('epic_num_reader.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = new_model.predict([X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.5779958e-08 5.4642879e-08 3.3342246e-06 5.3960743e-05 4.0838817e-09\n",
      " 7.2082429e-07 1.8156365e-13 9.9993849e-01 1.8937068e-07 3.1428424e-06]\n"
     ]
    }
   ],
   "source": [
    "print(pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(np.argmax(pred[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2050cc15390>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAADZ9JREFUeJzt3V2MXdV5xvHnYTIegw0EErAnxo0x0LTEaU06dUqpChEiIhWRyUVQfEFdKcJRFaSmQlWRb8JNJVQ1oUhNI02CEyMRkkhAsCJUQFYlGiVCDMgFUgfsuMa4/hgQUNs49nhm3l7Mdjoxc9YZztc+4/f/k6w5Z6/98fponlnnnLX3Xo4IAcjnnLoLAFAPwg8kRfiBpAg/kBThB5Ii/EBShB9IivADSRF+IKkP9PJgizwUi7Wkl4cEUjmhdzURJz2fddsKv+2bJd0vaUDSdyLi3tL6i7VEn/KN7RwSQMGzsX3e67b8tt/2gKRvSvqspKslbbB9dav7A9Bb7XzmXydpd0TsiYgJST+QtL4zZQHotnbCv0LS67Oe76+W/Rbbm2yP2R47pZNtHA5AJ7UT/rm+VHjP9cERMRoRIxExMqihNg4HoJPaCf9+SStnPb9M0oH2ygHQK+2E/zlJV9m+3PYiSV+UtK0zZQHotpaH+iJi0vadkp7UzFDfloj4RccqA9BVbY3zR8QTkp7oUC0AeojTe4GkCD+QFOEHkiL8QFKEH0iK8ANJEX4gKcIPJEX4gaQIP5AU4QeSIvxAUoQfSIrwA0kRfiApwg8kRfiBpAg/kBThB5Ii/EBShB9IivADSRF+ICnCDyRF+IGkCD+QFOEHkiL8QFKEH0iqrVl6be+VdFTSlKTJiBjpRFEAuq+t8Fc+HRFvdmA/AHqIt/1AUu2GPyQ9Zft525s6URCA3mj3bf91EXHA9qWSnrb9y4h4ZvYK1R+FTZK0WOe1eTgAndJWzx8RB6qf45Iek7RujnVGI2IkIkYGNdTO4QB0UMvht73E9vmnH0v6jKSXO1UYgO5q523/MkmP2T69n+9HxL91pCoAXddy+CNij6Q/7GAtAHqIoT4gKcIPJEX4gaQIP5AU4QeSIvxAUp24qi+FQ3/7pw3bTl57tLjtxPFFxfY4PlBsv/LhU8X2RbsPNmybPHiouC3youcHkiL8QFKEH0iK8ANJEX4gKcIPJEX4gaQY55+n//y7f23YNvq/Hyluu3bxa8X2d6bKtzfbfu3Hi+2PPnltw7al+1YXtz1nMortExe62K4mzZouHbvJpk1+O5ttP3lu47bzDpX/3xd/9+flnZ8F6PmBpAg/kBThB5Ii/EBShB9IivADSRF+ICnG+efpU3f/dcO2Ex8qD3afv2+q2P7OleXr+X89XBgslzQ4Udh2eXk8e+jtcu3HV5SPHc1OAyj81wcmyhu7fBsDTZdvk6CBy481bLvjE9uL2z7y3UvLOz8L0PMDSRF+ICnCDyRF+IGkCD+QFOEHkiL8QFJNx/ltb5F0i6TxiFhTLbtY0g8lrZK0V9JtEfF298qs3wcf7N713Uva3P6cJY334MuGi9vGa/vLO//dVS1UNEvhNAFPNBnIP/RGsXnPXWtaKGjGv7xyfbF9WDtb3vdCMZ+e/3uSbj5j2d2StkfEVZK2V88BLCBNwx8Rz0h664zF6yVtrR5vlXRrh+sC0GWtfuZfFhEHJan6efafCwmcZbp+br/tTZI2SdJile9VB6B3Wu35D9selqTq53ijFSNiNCJGImJkUEMtHg5Ap7Ua/m2SNlaPN0p6vDPlAOiVpuG3/bCkn0v6mO39tr8k6V5JN9neJemm6jmABaTpZ/6I2NCg6cYO14IWTb/7buPGV3a3t/MXf9ne9u1Y94li89RQ+V4F0wcan/+w+psNP6nO7LvYenbgDD8gKcIPJEX4gaQIP5AU4QeSIvxAUty6G7UZuOCCYvuv1i8t76DJbcNXbWt8yfDUrj3ljROg5weSIvxAUoQfSIrwA0kRfiApwg8kRfiBpBjnR22Offr3iu2T55Yv2R08Vh7oH3q98d3kM1yy2ww9P5AU4QeSIvxAUoQfSIrwA0kRfiApwg8kxTg/umrgY1c2bDt07UCTrcvj/KsfKk/hzTX7ZfT8QFKEH0iK8ANJEX4gKcIPJEX4gaQIP5BU03F+21sk3SJpPCLWVMvukXSHpNMDrZsj4oluFYmF68iaDzVsiyb33T9/b7lvmtr1362UhMp8ev7vSbp5juX3RcTa6h/BBxaYpuGPiGckvdWDWgD0UDuf+e+0/aLtLbYv6lhFAHqi1fB/S9IVktZKOijp641WtL3J9pjtsVM62eLhAHRaS+GPiMMRMRUR05K+LWldYd3RiBiJiJFBDbVaJ4AOayn8todnPf28pJc7Uw6AXpnPUN/Dkm6Q9GHb+yV9TdINttdq5prLvZK+3MUaAXRB0/BHxIY5Fj/QhVqwAHlwUbH9nSsbX7Pv6fL1+h95crzYPjXN3ffbwRl+QFKEH0iK8ANJEX4gKcIPJEX4gaS4dTfa8u4t1xTbf71sumHbha+Wr+mdemV3SzVhfuj5gaQIP5AU4QeSIvxAUoQfSIrwA0kRfiApxvlR5D/6eLH9wPXlsfqBE43bl28/XNyWC3a7i54fSIrwA0kRfiApwg8kRfiBpAg/kBThB5JinD+5c5YsKbbv/dyFxfZw4+v1JemCwiX5U7v2FLdFd9HzA0kRfiApwg8kRfiBpAg/kBThB5Ii/EBSTcf5ba+U9KCk5ZKmJY1GxP22L5b0Q0mrJO2VdFtEvN29UtESl6+3P3z7HxTbJz5YHscfervcfyz7ya8atk0Wt0S3zafnn5R0V0T8vqQ/kfQV21dLulvS9oi4StL26jmABaJp+CPiYES8UD0+KmmnpBWS1kvaWq22VdKt3SoSQOe9r8/8tldJukbSs5KWRcRBaeYPhKRLO10cgO6Zd/htL5X0iKSvRsSR97HdJttjtsdO6WQrNQLognmF3/agZoL/UEQ8Wi0+bHu4ah+WND7XthExGhEjETEyqKFO1AygA5qG37YlPSBpZ0R8Y1bTNkkbq8cbJT3e+fIAdMt8Lum9TtLtkl6yvaNatlnSvZJ+ZPtLkvZJ+kJ3SkQ7PrCs/FXMiUvKQ4FSFFs/+pPyJ8DJQ+Xbc6M+TcMfET+V1Og35MbOlgOgVzjDD0iK8ANJEX4gKcIPJEX4gaQIP5AUt+4+CwxccknDtn1/eUVb+175VHmi7Bh7ua39oz70/EBShB9IivADSRF+ICnCDyRF+IGkCD+QFOP8Z4Ej169u2HZqafl6/HNOla/nP+/VN4vt5bMA0M/o+YGkCD+QFOEHkiL8QFKEH0iK8ANJEX4gKcb5F4Dp668pth/+48Z/wweYIQ0N0PMDSRF+ICnCDyRF+IGkCD+QFOEHkiL8QFJNx/ltr5T0oKTlkqYljUbE/bbvkXSHpDeqVTdHxBPdKjSz8U+eW2yfXjTdsG3gZPl6/cEj5WP7xER5BSxY8znJZ1LSXRHxgu3zJT1v++mq7b6I+KfulQegW5qGPyIOSjpYPT5qe6ekFd0uDEB3va/P/LZXSbpG0rPVojttv2h7i+2LGmyzyfaY7bFT4lxToF/MO/y2l0p6RNJXI+KIpG9JukLSWs28M/j6XNtFxGhEjETEyKCGOlAygE6YV/htD2om+A9FxKOSFBGHI2IqIqYlfVvSuu6VCaDTmobftiU9IGlnRHxj1vLhWat9XhLTtQILyHy+7b9O0u2SXrK9o1q2WdIG22slhaS9kr7clQrRlsVvlof6hr+zo9g+efx4J8tBH5nPt/0/lTTXbxBj+sACxhl+QFKEH0iK8ANJEX4gKcIPJEX4gaS4dfcCsPy+n3Vt340vBsbZjp4fSIrwA0kRfiApwg8kRfiBpAg/kBThB5JyRPTuYPYbkl6btejDkt7sWQHvT7/W1q91SdTWqk7W9tGIuGQ+K/Y0/O85uD0WESO1FVDQr7X1a10StbWqrtp42w8kRfiBpOoO/2jNxy/p19r6tS6J2lpVS221fuYHUJ+6e34ANakl/LZvtv2K7d22766jhkZs77X9ku0dtsdqrmWL7XHbL89adrHtp23vqn7OOU1aTbXdY/t/qtduh+2/qKm2lbb/3fZO27+w/TfV8lpfu0JdtbxuPX/bb3tA0quSbpK0X9JzkjZExH/1tJAGbO+VNBIRtY8J2/5zScckPRgRa6pl/yjprYi4t/rDeVFE/H2f1HaPpGN1z9xcTSgzPHtmaUm3Svor1fjaFeq6TTW8bnX0/Osk7Y6IPRExIekHktbXUEffi4hnJL11xuL1krZWj7dq5pen5xrU1hci4mBEvFA9Pirp9MzStb52hbpqUUf4V0h6fdbz/eqvKb9D0lO2n7e9qe5i5rCsmjb99PTpl9Zcz5maztzcS2fMLN03r10rM153Wh3hn2v2n34acrguIj4p6bOSvlK9vcX8zGvm5l6ZY2bpvtDqjNedVkf490taOev5ZZIO1FDHnCLiQPVzXNJj6r/Zhw+fniS1+jlecz2/0U8zN881s7T64LXrpxmv6wj/c5Kusn257UWSvihpWw11vIftJdUXMbK9RNJn1H+zD2+TtLF6vFHS4zXW8lv6ZebmRjNLq+bXrt9mvK7lJJ9qKOOfJQ1I2hIR/9DzIuZge7Vmentp5s7G36+zNtsPS7pBM1d9HZb0NUk/lvQjSb8jaZ+kL0REz794a1DbDZp56/qbmZtPf8bucW1/Juk/JL2k/79B8WbNfL6u7bUr1LVBNbxunOEHJMUZfkBShB9IivADSRF+ICnCDyRF+IGkCD+QFOEHkvo/YH/Gn1C2k9gAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
